{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parser_links2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QLGDxikeWl6N"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ = 'https://mislitel.info/authors'\n",
        "links = []\n",
        "\n",
        "# выберем первые 5 страниц, чтобы избежать большого числа ноунеймов в датасете\n",
        "for i in range(1,6):\n",
        "\n",
        "    if i == 1:\n",
        "        url = url_\n",
        "    else:\n",
        "        url = url_ + '?page=' + str(i)\n",
        "\n",
        "    data = requests.get(url)\n",
        "    soup = BeautifulSoup(data.text, \"lxml\")\n",
        "    sp = soup.findAll('td', class_ = 'razd-row')\n",
        "\n",
        "    for i in sp:\n",
        "        href = 'https://mislitel.info' + i.find('a').get('href')\n",
        "        links.append(href)"
      ],
      "metadata": {
        "id": "7cZQF95qXKjR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('links2.pickle', 'wb') as f:\n",
        "    pickle.dump(links, f)"
      ],
      "metadata": {
        "id": "afYbLvB1X-7Z"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}